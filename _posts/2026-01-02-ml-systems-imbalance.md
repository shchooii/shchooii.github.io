---
title: ML Systems Imbalance
date: 2026-01-02 20:23:12 +09:00
categories: ['mlops']
tags: ['mlops', 'class imbalance', 'augmentation'] 
math: true
---

현업에서 다루는 데이터는 대개 균형 잡힌 분포가 아니라 쏠린 분포에 가깝습니다. 
클래스 불균형이 왜 모델 학습을 어렵게 만드는지, 그리고 이를 완화하기 위해 평가 지표, 데이터 분포, 학습 알고리즘을 어떤 관점으로 조정해야 하는지 알아보겠습니다.

## Class Imbalance

### 개념과 범위

클래스 불균형(class imbalance)은 분류 문제에서 클래스별 샘플 수가 크게 차이나는 상황을 의미합니다. 
예를 들어 X-ray로 폐암을 탐지하는 문제에서 정상(normal)이 99.99%, 암(cancer)이 0.01%일 수 있습니다. 
이때 모델은 정상만 찍어도 성능이 높아질 수 있어 학습과 평가 모두를 왜곡합니다.

불균형은 분류에만 국한되지 않습니다. 회귀(regression)에서도 라벨 분포가 치우치면 비슷한 현상이 발생합니다. 
의료비 청구액처럼 분포가 오른쪽으로 길게 늘어진(skewed) 경우, 중앙값 근처의 예측보다 상위 분위수(예: 95th percentile) 영역에서의 오차가 훨씬 중요할 수 있습니다. 같은 100% 오차라도 $$250 \rightarrow 500$$과 $$10k \rightarrow 20k$$는 실무적 의미가 다릅니다. 
따라서 전체 평균 지표가 아니라 중요한 구간에서의 성능을 목표로 재정의해야 합니다.

### Class Imbalance가 어려운 이유

클래스 불균형이 학습을 어렵게 만드는 이유는 크게 세 가지 흐름으로 정리할 수 있습니다.

소수 클래스 샘플이 극단적으로 적으면 모델은 그 클래스를 몇 번 보지도 못하고 결정을 내려야 하므로 사실상 few-shot learning 문제가 됩니다. 
극단적으로는 학습 데이터에 희귀 클래스가 아예 없어서, 모델이 그 클래스는 존재하지 않는다고 가정하게 될 수도 있습니다.

비최적해에 머물기 쉬워집니다. 폐암 탐지 예시에서 항상 다수 클래스(정상)만 출력해도 정확도는 99.99%입니다. 
이런 단순 휴리스틱은 경사하강법 기반 학습이 이기기 어렵습니다. 왜냐하면 그 휴리스틱에서 약간만 벗어나도(소수 클래스를 맞추려다) 오히려 전체 정확도가 나빠질 수 있기 때문입니다. 
최적화 관점에서 쉽게 먹히는 지름길이 존재하여 모델이 의미 있는 패턴 학습을 회피할 수 있습니다.

오류 비용이 비대칭(asymmetric cost)입니다. 희귀 클래스에서의 오답 비용이 다수 클래스의 오답 비용보다 훨씬 큰 경우가 많습니다. 암을 놓치는 경우(거짓 음성, false negative)는 정상인데 암이라고 판단하는 경우(거짓 양성, false positive)보다 위험할 수 있습니다. 
손실 함수가 이 비대칭을 반영하지 않으면 모델은 모든 샘플을 동일하게 취급하며, 실무적으로 원하는 형태(다수 클래스 성능 일부를 희생하더라도 소수 클래스 성능을 크게 올리는 형태)를 얻기 어렵습니다.

### 불균형이 흔한 이유와 원인 진단

현실에서는 희귀 이벤트가 더 위험하기 때문에, 불균형은 예외가 아니라 규범이 됩니다. 
사기 탐지(fraud detection), 이탈 예측(churn prediction), 질병 스크리닝, 이력서 스크리닝, 객체 탐지(object detection) 등은 본질적으로 불균형 구조를 갖습니다.

불균형은 샘플링 편향 때문에 인위적으로 생길 수도 있습니다. 이메일 스팸 탐지를 위해 기업 메일 DB를 수집하면, 이미 필터링된 뒤의 이메일만 남아 스팸 비중이 실제보다 훨씬 낮아질 수 있습니다. 
라벨링 오류로도 불균형이 생길 수 있으므로, 불균형을 발견하면 원인이 무엇인지를 먼저 확인해야 합니다. 단순히 기법을 적용하기 전에 데이터 수집·필터링·라벨링 과정을 점검하는 것이 중요합니다.

## Handling Class Imbalance

불균형 완화는 크게 세 갈래로 설명됩니다.

1) 적절한 평가 지표를 선택합니다.
2) 데이터 레벨에서 분포를 조정합니다(resampling).
3) 알고리즘 레벨에서 학습을 조정합니다(loss/weighting 등).

### Using the right evaluation metrics

불균형 문제에서 가장 먼저 해야 할 일은 평가 지표를 제대로 고르는 것입니다. 잘못된 지표는 모델이 좋아지고 있는지 나빠지고 있는지조차 오판하게 만듭니다.

전체 정확도(accuracy)와 오류율(error rate)은 불균형에서 좋은 지표가 아닙니다. 다수 클래스가 지표를 지배하므로, 소수 클래스에서 완전히 실패해도 정확도가 높게 나올 수 있습니다.

#### 혼동행렬과 정확도의 함정

양성 클래스(예: CANCER)와 음성 클래스(예: NORMAL)가 있고, 데이터의 90%가 NORMAL이라고 가정합니다. 
두 모델 A와 B가 다음과 같은 혼동행렬을 가질 수 있습니다.

모델 A는 CANCER 100개 중 10개만 맞춥니다.

- Predicted CANCER / Actual CANCER: 10 (TP)
- Predicted CANCER / Actual NORMAL: 10 (FP)
- Predicted NORMAL / Actual CANCER: 90 (FN)
- Predicted NORMAL / Actual NORMAL: 890 (TN)

모델 B는 CANCER 100개 중 90개를 맞춥니다.

- TP: 90, FP: 90, FN: 10, TN: 810

둘 다 정확도는 $$(TP+TN)/(TP+FP+FN+TN)=0.9$$로 같을 수 있습니다. 
그러나 실제로는 모델 B가 의료적 관점에서 훨씬 유용합니다. 따라서 클래스별 성능을 분리해서 봐야 합니다.

#### Precision, Recall, F1

이진 분류에서 정밀도(precision), 재현율(recall), F1은 양성 클래스에 초점을 둡니다. 다음 표기에서 TP, FP, FN, TN을 사용합니다.

- Precision:
  $$
  \text{Precision} = \frac{TP}{TP + FP}
  $$

- Recall:
  $$
  \text{Recall} = \frac{TP}{TP + FN}
  $$

- F1:
  $$
  \text{F1} = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
  $$

이 지표들은 어느 클래스를 양성으로 보느냐에 따라 값이 달라지는 비대칭 지표입니다. 예를 들어 NORMAL을 양성으로 보면 모델 A의 F1이 매우 높아질 수 있습니다. 
불균형 문제에서는 관심 클래스가 무엇인지를 먼저 고정하고, 그 클래스 기준으로 지표를 해석해야 합니다.

#### ROC curve, AUC, Precision-Recall curve

모델이 확률을 출력하고 임계값(threshold)으로 분류하는 경우, 임계값을 바꾸면 TPR(재현율)과 FPR(거짓 양성률)이 바뀝니다. 이를 여러 임계값에 대해 그린 것이 ROC curve입니다.

- $$
  \text{TPR} = \frac{TP}{TP+FN}
  $$

- $$
  \text{FPR} = \frac{FP}{FP+TN}
  $$

ROC curve 아래 면적이 AUC입니다. 그러나 불균형이 심할수록 PR curve(Precision-Recall curve)가 더 직관적인 정보를 줄 수 있다는 논의가 있습니다. 
PR curve는 소수 클래스에서의 정밀도-재현율 trade-off를 직접 보여주기 때문입니다.

### Data-level methods: Resampling

데이터 레벨 방법은 학습 데이터 분포를 덜 불균형하게 만들어 모델이 학습하기 쉽게 돕습니다. 대표적으로 undersampling과 oversampling이 있습니다.

- Undersampling: 다수 클래스를 줄입니다.
- Oversampling: 소수 클래스를 늘립니다(복제 또는 합성).

가장 단순한 방식은 랜덤 제거(undersampling)와 랜덤 복제(oversampling)입니다. 다만 undersampling은 중요한 정보를 잃을 수 있고, oversampling은 소수 클래스 복제본에 과적합할 위험이 있습니다.

#### Tomek links (undersampling)

Tomek links는 서로 다른 클래스 쌍 중 가장 가까운 샘플 쌍을 찾고, 그 중 다수 클래스 샘플을 제거하는 방식입니다. 결정 경계를 더 또렷하게 만들 수 있지만, 진짜 경계의 미세한 구조를 덜 보게 되어 강건성이 떨어질 수 있습니다.

#### SMOTE (oversampling)

SMOTE는 소수 클래스 내부에서 기존 샘플들의 볼록 결합(convex combination)을 이용해 새로운 샘플을 합성합니다. 직관적으로는 소수 클래스 샘플 사이를 보간(interpolation)해서 가상의 샘플을 만드는 것입니다.

예를 들어 소수 클래스 샘플 $x_a, x_b$가 있을 때,
$$
x_{\text{new}} = \lambda x_a + (1-\lambda) x_b,\quad 0 \le \lambda \le 1
$$
처럼 생성합니다.

주의할 점은, SMOTE나 Tomek links는 주로 저차원에서 검증된 방법이며, 고차원(딥러닝 임베딩 공간)에서는 거리 계산이나 경계 추정이 비싸거나 불안정할 수 있다는 점입니다.

#### Resampling 시 주의사항과 변형 기법

Resampling된 분포로 평가하면 안 됩니다. 평가 데이터는 원래 분포를 유지해야 하며, 그렇지 않으면 모델이 resampled 분포에 과적합한 것처럼 보일 수 있습니다.

이를 완화하기 위해 다음과 같은 변형 기법이 제안됩니다.

- Two-phase learning:  
  1단계에서 resampled 데이터로 학습하여 소수 클래스를 충분히 보게 하고, 2단계에서 원래 데이터로 fine-tune하여 실제 분포에 적응합니다.

- Dynamic sampling:  
  학습 중에 클래스별 성능을 보고, 성능이 낮은 클래스를 더 자주 보여주고 성능이 높은 클래스를 덜 보여주는 방식입니다. 목표는 이미 배운 것은 덜, 못 배운 것은 더 노출시키는 것입니다.

---

### Algorithm-level methods

알고리즘 레벨 방법은 데이터 분포는 그대로 두고, 학습 규칙을 바꿉니다. 핵심은 손실 함수가 학습을 이끄는 역할을 하므로, 어떤 샘플/클래스의 손실을 더 크게 보게 만들면 모델이 그 부분을 더 우선적으로 학습한다는 점입니다.

기본적인 평균 손실은 다음처럼 표현됩니다. 학습 샘플 수를 $$N$$이라 하고, 각 샘플 $$x$$에 대해 모델 파라미터 $$\theta$$에서의 손실을 $$L(x;\theta)$$라 하면,

$$
L(X;\theta) = \frac{1}{N}\sum_{x} L(x;\theta)
$$

이 표현은 모든 샘플을 동일하게 취급합니다. 불균형에서 문제가 되는 지점은 바로 이 동일 취급입니다.

#### Cost-sensitive learning

클래스 $$i$$를 $$j$$로 잘못 분류했을 때의 비용을 $$C_{ij}$$로 둔 비용 행렬(cost matrix)을 사용합니다. 
이때 각 샘플의 기대 비용 기반 손실은 다음처럼 쓸 수 있습니다.

$$
L(x;\theta) = \sum_j C_{ij} P(j \mid x; \theta)
$$

여기서 $$i$$는 정답 클래스이며, $$P(j \mid x; \theta)$$는 모델이 $$j$$로 분류할 확률입니다. 단점은 비용 행렬을 사람이 설계해야 하고, 업무 맥락에 따라 스케일이 달라진다는 점입니다.

#### Class-balanced loss

간단한 형태로 클래스 가중치를 샘플 수의 역수로 줄 수 있습니다. 클래스 $$i$$의 샘플 수를 $$n_i$$, 전체 샘플 수를 $$N$$이라 하면,

$$
W_i = \frac{N}{n_i}
$$

정답 클래스가 $$i$$인 샘플 $$x$$의 손실을 $$W_i$$로 스케일링합니다.

$$
L(x;\theta) = W_i \sum_j P(j \mid x;\theta)\, \text{Loss}(x, j)
$$

여기서 $$\text{Loss}(x,j)$$는 cross entropy 등 기본 손실을 의미합니다. 더 발전된 형태로 유효 샘플 수(effective number of samples)를 고려하여 중복/겹침을 반영하는 방식도 있습니다.

#### Focal loss

Focal loss는 이미 쉽게 맞추는 샘플의 영향은 줄이고, 어려운 샘플의 영향은 키우는 아이디어입니다. 즉, 모델이 확신하는 쉬운 샘플에 덜 집중하고, 아직 헷갈리는 샘플에 더 집중하도록 합니다.

이때 핵심은 정답 확률이 낮을수록 더 큰 가중이 걸리도록 손실을 조정한다는 점입니다.

## Data Augmentation

### 목적과 배경

데이터 증강은 학습 데이터를 더 많이 만들거나 더 다양한 변형을 보게 만들어 모델을 더 강건하게 만드는 기법들의 묶음입니다. 전통적으로는 의료영상처럼 데이터가 적은 영역에서 중요했지만, 최근에는 데이터가 많아도 증강이 잡음과 적대적 공격에 대한 강건성을 높인다는 이유로 표준적인 구성 요소가 되었습니다.

이 절에서는 세 가지 축으로 정리합니다.

- 단순한 라벨 보존 변환(label-preserving transformations)
- 퍼터베이션(perturbation)과 적대적 증강(adversarial augmentation)
- 데이터 합성(data synthesis)

### Simple Label-Preserving Transformations

#### Computer Vision

이미지에서 라벨을 유지하면서 픽셀 구성을 바꾸는 변환을 적용합니다. 예를 들면 crop, flip, rotate, invert, random erasing 등이 있습니다. 개는 회전해도 개라는 직관이 성립할 때 효과적입니다.

실무적으로 중요한 포인트는 증강이 계산 비용을 크게 늘리지 않도록 파이프라인을 구성하는 것입니다. 예를 들어 CPU에서 다음 배치의 증강을 만드는 동안 GPU는 이전 배치를 학습하는 구조로 오버랩하면, 체감 비용을 줄일 수 있습니다.

#### NLP

문장 의미를 크게 해치지 않는 범위에서 단어를 유사어로 바꾸거나(동의어 사전, 임베딩 근접도 활용), 표현을 약간 변형하여 데이터 다양성을 늘립니다. 예시는 다음처럼 이해할 수 있습니다.

- I’m so happy to see you.
- I’m so glad to see you.
- I’m very happy to see you.

다만 NLP에서는 라벨 보존이 이미지보다 훨씬 까다롭습니다. 단어 치환이 뉘앙스를 바꾸거나 문장을 부자연스럽게 만들 수 있으므로, 품질 관리가 중요합니다.

---

### Perturbation

퍼터베이션은 라벨 보존 변환의 한 종류이지만, 작은 잡음이 모델을 쉽게 속일 수 있다는 점에서 별도 주제로 다룹니다.

신경망은 작은 노이즈에 민감할 수 있습니다. 한 픽셀만 바꿔도 분류가 바뀌는 사례가 보고됩니다. 이런 공격을 adversarial attack이라 하고, 노이즈를 이용해 의도적으로 오분류를 유도합니다.

#### Adversarial augmentation

오히려 이런 속이기 쉬운 약점을 학습 중에 노출시키면, 모델이 결정 경계의 취약점을 보완할 수 있습니다. 노이즈를 만드는 방식은 두 가지 흐름이 있습니다.

- 랜덤 노이즈 추가
- 탐색 기반 노이즈(최소한의 노이즈로 오분류를 만드는 방향을 찾음)

예를 들어 DeepFool은 고신뢰 오분류를 유도하기 위해 필요한 최소 노이즈를 찾는 방식으로 소개됩니다. 이런 방식으로 만든 샘플을 학습에 포함시키는 것을 적대적 증강이라 부릅니다.

#### NLP에서의 퍼터베이션

NLP는 무작위 문자/단어 추가가 문장을 쉽게 망가뜨리므로 이미지처럼 단순 노이즈 주입이 어렵습니다. 그럼에도 불구하고 모델 강건성을 위해 제한된 형태의 퍼터베이션이 사용됩니다.

예를 들어 BERT의 마스킹/치환 아이디어는 일부 토큰을 선택해 일부는 무작위 단어로 치환합니다. 문장이 부분적으로 비문이 될 수 있지만, 소량의 노이즈가 표현 학습에 도움이 되는 것으로 보고됩니다.

### Data Synthesis

데이터 합성은 진짜 데이터를 수집하는 비용을 줄이거나, 특정 상황의 데이터를 보강하기 위해 인공적으로 데이터를 생성하는 접근입니다. 아직 모든 데이터를 대체할 정도로 일반적이지는 않지만, 특정 영역에서 성능 향상 사례가 있습니다.

#### NLP: 템플릿 기반 합성

대화형 AI나 검색 질의처럼 형식이 반복되는 데이터는 템플릿으로 빠르게 부트스트랩할 수 있습니다.

- Template: Find me a [CUISINE] restaurant within [NUMBER] miles of [LOCATION].
- Generated: Find me a Vietnamese restaurant within 2 miles of my office.

핵심은 라벨이 자연스럽게 따라오는 구조를 설계해, 적은 비용으로 다양한 변형을 만들 수 있다는 점입니다.

#### Computer Vision: mixup

mixup은 두 샘플 $$x_1, x_2$$를 섞어 새로운 샘플 $x'$를 만들고, 라벨도 연속적으로 섞는 방식입니다.

$$
x' = \gamma x_1 + (1-\gamma) x_2,\quad 0 \le \gamma \le 1
$$

이때 라벨도 동일한 비율로 섞습니다. 

예를 들어 DOG=0, CAT=1이면,

$$
y' = \gamma\cdot 0 + (1-\gamma)\cdot 1 = 1-\gamma
$$

mixup은 일반화 성능 향상, 라벨 노이즈에 대한 완화, 적대적 예제에 대한 강건성, 학습 안정화 등에 도움이 될 수 있다고 보고됩니다.

#### 생성모델 기반 합성

GAN/CycleGAN 같은 생성 모델을 사용해 합성 이미지를 만들어 학습 데이터에 추가하는 접근도 소개됩니다. CT 세그멘테이션에서 CycleGAN으로 생성한 이미지를 추가해 성능이 개선된 사례가 언급됩니다. 다만 생산 환경에서 보편적이라고 보기엔 아직 연구 및 도입 비용이 크며, 품질 관리가 핵심 이슈입니다.

## 맺음말

> 클래스 불균형은 단순히 데이터가 한쪽으로 많다는 문제가 아니라, 학습 신호의 부족, 최적화의 함정, 오류 비용 비대칭이라는 구조적 어려움을 동반합니다. 
> 따라서 지표를 잘못 고르면 모델이 좋아지고 있다는 착각을 하기 쉽고, 데이터 분포를 조정하거나 손실을 조정해 학습의 우선순위를 바꾸어야 합니다. 
> 데이터 증강은 데이터 부족을 보완하는 전통적 역할을 넘어, 모델을 잡음과 공격에 강건하게 만드는 표준 기술로 확장되었습니다. 
> 이 두 축을 함께 이해하면, 실제 시스템에서 무엇을 개선해야 하는지를 더 정확히 판단할 수 있게 됩니다.
