---
title: ML Systems Sampling
date: 2025-12-21 19:22:12 +09:00
categories: ['mlops']
tags: ['mlops', 'sampling', 'weighted', 'stratified', 'reservoir']
math: true
---

머신러닝 시스템에서 훈련 데이터를 다루는 관점을 데이터 과학 관점으로 정리한 내용입니다. 
모델링은 흥미롭지만, 실제 프로젝트에서는 데이터 수집·정제·샘플링 단계가 전체 성패를 좌우하는 경우가 많습니다. 
데이터는 종종 형식이 제각각이고, 결측·오염·편향이 섞여 있으며, 메모리에 올리기조차 어려운 크기로 유입되기도 합니다.
이러한 특성 때문에 데이터 처리를 소홀히 하면 모델 품질뿐 아니라 개발·운영 비용과 일정까지 크게 악화될 수 있습니다.

실제 운영 데이터는 유한하고 정적인 “데이터셋”이라기보다 시간에 따라 분포가 변하고 계속 생성되는 “데이터”에 가깝습니다. 
따라서 훈련 데이터 구성은 일회성 작업이 아니라, 시스템·요구사항·모델이 바뀔 때마다 반복적으로 정련되는 과정으로 이해하는 것이 바람직합니다.

## 훈련 데이터의 범위와 기본 관점

훈련 데이터는 모델 개발 단계에서 사용되는 모든 데이터(훈련/검증/테스트 분할 포함)를 의미합니다. 일반적으로 다음과 같은 관점이 중요합니다.

- 데이터는 완전하지 않다는 전제를 둬야 합니다. 결측, 중복, 노이즈, 라벨 오류, 샘플링 편향이 항상 존재한다고 가정하는 편이 안전합니다.
- 데이터는 편향을 품고 있을 수 있습니다. 수집·샘플링·라벨링 과정에서 편향이 유입되며, 모델은 이를 학습해 재생산할 수 있습니다.
- 훈련 데이터는 모델과 함께 진화합니다. 실험 결과에 따라 더 필요해지는 슬라이스가 생기고, 실패 패턴에 맞춰 재수집·재샘플링이 발생합니다.

---

## Sampling

샘플링은 전체 가능한 현실 데이터에서 훈련 데이터를 고르는 과정, 주어진 데이터에서 train/val/test split을 만드는 과정, 운영 중 이벤트를 추출해 모니터링하는 과정 등 다양한 단계에서 발생합니다. 
여기서는 훈련 데이터 구성을 위한 샘플링을 중심으로 정리합니다.

샘플링이 필요한 대표 상황은 다음과 같습니다.

- 현실 세계의 모든 데이터를 확보할 수 없어 부분집합만 사용해야 하는 경우입니다.
- 확보한 데이터가 너무 크거나 비싸서 전량 처리(학습/정제)가 불가능한 경우입니다.
- 새로운 아이디어를 빠르게 검증하기 위해 작은 서브셋으로 선행 실험을 하는 경우입니다.

샘플링 방법을 이해하면 샘플링 편향을 줄이고, 제한된 자원에서 더 효율적으로 데이터를 사용하도록 설계할 수 있습니다. 샘플링은 크게 비확률(nonprobability) 샘플링과 확률 기반(random/probability) 샘플링으로 구분합니다.

## 샘플링 편향과 추정 관점

샘플링을 데이터 선택 문제로만 보면 “데이터를 몇 개 뽑는가”로 끝나기 쉽지만, 통계적 관점에서는 “어떤 값을 얼마나 정확히 추정하는가”가 핵심이 됩니다. 
예를 들어 어떤 지표(평균 손실, 특정 클래스의 빈도, 오류율)를 모집단에서 추정한다고 할 때, 샘플링 편향이 있으면 추정값이 체계적으로 틀어질 수 있습니다.

- 모집단(population)을 $$ \mathcal{D} $$ 라 하고, 샘플링으로 얻는 데이터 분포를 $$ \tilde{\mathcal{D}} $$ 라 하면, $$ \tilde{\mathcal{D}} \neq \mathcal{D} $$인 상황이 흔합니다.
- 이때 모델은 $$ \tilde{\mathcal{D}} $$ 에 최적화되어 $$ \mathcal{D} $$에서 성능이 떨어질 수 있습니다.

대표적으로, 어떤 함수 $$ f(x) $$의 모집단 기대값을 추정한다고 할 때,

$$
\mu = \mathbb{E}_{x \sim \mathcal{D}}[f(x)]
$$

단순 평균 추정량은 표본이 모집단을 대표한다는 가정 하에서만 타당합니다.

$$
\hat{\mu}_{\text{naive}} = \frac{1}{n}\sum_{i=1}^{n} f(x_i)
$$

샘플링이 편향되어 있으면 $$\hat{\mu}_{\text{naive}}$$는 $$\mu$$의 편향 추정량이 될 수 있습니다. 
이후에 다루는 층화, 가중, 중요도 샘플링은 “표본 선택”뿐 아니라 “추정의 보정” 관점에서 함께 이해하는 것이 유용합니다.

## Nonprobability Sampling

비확률 샘플링은 어떤 확률 기준에 의해 표본이 선택되지 않는 방식입니다. 대표적인 형태는 다음과 같습니다.

- 편의 샘플링(convenience sampling)입니다. 접근 가능한 데이터부터 고르는 방식입니다.
- 스노우볼 샘플링(snowball sampling)입니다. 현재 표본이 연결하는 다음 표본을 확장 수집하는 방식입니다.
- 판단 샘플링(judgment sampling)입니다. 전문가 판단으로 포함 대상을 고르는 방식입니다.
- 할당 샘플링(quota sampling)입니다. 특정 슬라이스별 목표 개수를 맞추되 무작위화는 하지 않는 방식입니다.

비확률 샘플링은 빠르게 시작할 수 있다는 장점이 있으나, 표본이 모집단을 대표하지 못할 가능성이 커서 선택 편향(selection bias)에 취약합니다. 
실제로 “수집이 쉬운 데이터”가 초기 데이터가 되는 경우가 많고, 이후 모델이 특정 사용자군/지역/상황에 취약한 형태로 굳어지는 문제가 발생할 수 있습니다. 
초기 프로토타이핑에는 유용할 수 있으나, 신뢰 가능한 모델을 목표로 한다면 확률 기반 샘플링으로 전환하거나, 편향을 측정·보정하는 체계를 함께 갖추는 편이 안전합니다.

## Simple Random Sampling

단순 무작위 샘플링은 모집단의 모든 샘플이 동일한 확률로 선택되는 방식입니다. 모집단 크기를 $$N$$, 표본 크기를 $$n$$이라 할 때, 각 샘플이 선택될 확률을 대략 $$n/N$$로 동일하게 둔다는 직관으로 이해할 수 있습니다.

장점은 구현이 단순하다는 점입니다. 단점은 희소 범주가 표본에서 빠질 위험이 크다는 점입니다. 어떤 클래스가 모집단에서 비율 $$p$$로 존재할 때, 단순 무작위로 $$n$$개를 뽑았을 때 그 클래스가 한 번도 등장하지 않을 확률은 이항 근사를 사용하면 다음처럼 표현할 수 있습니다.

$$
\Pr(\text{no sample of the class}) = (1-p)^n
$$

희소 클래스에서 $$p$$가 매우 작으면, $$n$$이 충분히 크지 않을 때 위 확률이 무시할 수 없게 됩니다. 이 상황에서는 학습 데이터에 희소 클래스가 거의 포함되지 않아, 모델이 해당 클래스를 사실상 학습하지 못하는 문제가 발생할 수 있습니다.

## Stratified Sampling

층화 샘플링은 모집단을 관심 있는 그룹(계층, stratum)으로 나눈 뒤, 각 계층에서 별도로 샘플링하는 방식입니다. 희소 범주 누락을 줄이기 위한 대표 방법입니다.

모집단을 $$H$$개의 계층으로 나누고, 계층 $$h$$의 크기를 $$N_h$$, 그 계층에서 뽑는 표본 수를 $$n_h$$라 하면,

$$
\sum_{h=1}^{H} N_h = N,\quad \sum_{h=1}^{H} n_h = n
$$

계층별로 같은 비율로 뽑는 비례 할당(proportional allocation)은 다음을 만족합니다.

$$
\frac{n_h}{n} = \frac{N_h}{N}
$$

희소 계층을 더 많이 확보하고 싶다면, 비례 할당 대신 목적 기반 할당을 사용할 수 있습니다. 예를 들어 tail 클래스 계층은 더 크게 뽑고 head 계층은 덜 뽑는 방식입니다. 이때 중요한 점은 “선택은 다르게 하되, 추정과 학습에서 이를 어떻게 보정할지”를 함께 설계해야 한다는 점입니다.

층화 샘플링으로 모집단 평균 $$\mu$$를 추정할 때, 계층 평균을 $$\mu_h$$라 하면 모집단 평균은

$$
\mu = \sum_{h=1}^{H} \frac{N_h}{N}\,\mu_h
$$

계층별 표본 평균 $$\bar{f}_h = \frac{1}{n_h}\sum_{i \in S_h} f(x_i)$$를 사용하면 층화 추정량은

$$
\hat{\mu}_{\text{strat}} = \sum_{h=1}^{H} \frac{N_h}{N}\,\bar{f}_h
$$

으로 쓸 수 있습니다. 계층별로 충분히 표본을 확보하면 희소 범주에 대한 추정 안정성이 좋아집니다.

다만 멀티라벨 문제처럼 한 샘플이 여러 계층에 동시에 속하는 경우, 계층 정의가 애매해지고, 계층 간 중복을 어떻게 처리할지(우선순위, 다중 계층 표본화, 샘플 가중치로 해결 등) 설계가 어려워집니다.

## Weighted Sampling

가중 샘플링은 각 샘플 $$x_i$$에 가중치 $$w_i \ge 0$$를 부여하고, 그 가중치에 비례해 선택 확률을 결정하는 방식입니다. 선택 확률은 다음처럼 정의할 수 있습니다.

$$
\Pr(x_i \text{ selected}) \propto w_i,\quad
\Pr(x_i)=\frac{w_i}{\sum_j w_j}
$$

도메인 지식을 반영할 수 있다는 점이 핵심 장점입니다. 예를 들어 최신 데이터가 더 중요하다고 판단되면 최신 샘플의 가중치를 높여 “선택” 자체를 최신 위주로 만들 수 있습니다. 관측 분포가 현실 분포와 다를 때도 가중치로 보정하는 설계가 가능합니다.

가중 샘플링과 샘플 가중치(sample weights)는 구분하는 것이 중요합니다.

- 가중 샘플링은 학습에 포함할 샘플을 뽑는 과정입니다.
- 샘플 가중치는 손실함수에서 샘플의 영향력을 조정하는 과정입니다.

샘플 가중치까지 포함하면, 경험적 위험 최소화(ERM)는 다음처럼 표현할 수 있습니다.

$$
\hat{R}(\theta) = \frac{1}{\sum_{i=1}^{n} \alpha_i}\sum_{i=1}^{n}\alpha_i\,\ell\big(g_\theta(x_i), y_i\big)
$$

여기서 $$\alpha_i$$는 학습 손실에서의 샘플 중요도입니다. $$\alpha_i$$는 샘플링 가중치 $$w_i$$와 같을 수도 있지만, 반드시 같을 필요는 없습니다. 예를 들어 선택은 균등하게 하되, 희소 클래스 샘플의 손실 가중치만 높일 수도 있습니다.

또한 분포 보정 관점에서는 “표본이 어떤 분포에서 왔는지”를 고려해 손실을 재가중하는 경우가 많습니다. 예를 들어 목표 분포가 $$P(x)$$, 샘플링 분포가 $$Q(x)$$라면, 경험적 기대손실을 다음처럼 보정하는 형태로 연결됩니다.

$$
\mathbb{E}_{x \sim P}[\ell(x)] = \mathbb{E}_{x \sim Q}\left[\ell(x)\frac{P(x)}{Q(x)}\right]
$$

이는 중요도 샘플링과 같은 수식 구조를 가집니다.

## Reservoir Sampling

리저버 샘플링은 스트리밍 데이터처럼 전체 길이를 모르거나 메모리에 모두 담을 수 없는 상황에서, 전체 스트림에서 균등 확률로 $$k$$개를 유지하기 위한 알고리즘입니다. 원하는 조건은 다음과 같습니다.

- 스트림의 각 원소가 동일한 확률로 선택되어야 합니다.
- 언제 중단해도 리저버가 올바른 확률로 샘플링되어 있어야 합니다.

절차는 다음과 같이 설명할 수 있습니다.

- 처음 $$k$$개 항목을 리저버에 채웁니다.
- $$n$$번째로 들어오는 새 항목마다, $$1$$ 이상 $$n$$ 이하의 정수 $$i$$를 균등하게 뽑습니다.
- $$1 \le i \le k$$이면 리저버의 $$i$$번째 항목을 $$n$$번째 항목으로 교체하고, 그렇지 않으면 아무 것도 하지 않습니다.

확률 성질을 간단히 적으면 다음과 같습니다.

- $$n$$번째 항목이 들어올 때 리저버에 들어갈 확률은 $$\frac{k}{n}$$ 입니다.
- $$n$$번째 시점에서 리저버 안의 임의의 항목이 “특정 과거 항목 $$j$$”일 확률도 $$\frac{k}{n}$$가 됩니다.

두 번째 항목은 직관적으로 다음처럼 확인할 수 있습니다. 어떤 $$j \le n$$가 리저버에 남아 있으려면, $$j$$가 리저버에 들어간 뒤(초기 $$k$$개면 자동, 이후면 $$\frac{k}{j}$$), 이후 시점 $$t=j+1,\dots,n$$에서 교체되지 않아야 합니다. 시점 $$t$$에서 교체될 확률은 $$\frac{k}{t}$$이고, 특정 위치(리저버 내 $$k$$개 슬롯 중 하나)가 교체될 확률은 $$\frac{1}{t}$$로 볼 수 있어, 전체적으로 $$\frac{k}{n}$$의 균등성이 유지됩니다. 이 성질 때문에 스트리밍 환경에서 샘플을 “대표성 있게” 유지하는 기본 도구로 자주 사용됩니다.

## Importance Sampling

중요도 샘플링은 목표 분포 $$P(x)$$에서 샘플링해야 하지만, 그 샘플링이 매우 비싸거나 불가능하여 대신 접근 가능한 분포 $$Q(x)$$에서 샘플링하고 가중치로 보정하는 방법입니다. $$Q(x)$$는 제안 분포(proposal distribution)이며 다음 조건이 필요합니다.

$$
P(x)\neq 0 \Rightarrow Q(x) > 0
$$

핵심은 기대값을 다음처럼 바꾸는 것입니다.

$$
\mathbb{E}_{P(x)}[f(x)]
= \sum_x P(x) f(x)
= \sum_x Q(x) f(x)\frac{P(x)}{Q(x)}
= \mathbb{E}_{Q(x)}\left[f(x)\frac{P(x)}{Q(x)}\right]
$$

따라서 $$x \sim Q$$로 샘플링하고, 각 샘플에 중요도 가중치

$$
w(x) = \frac{P(x)}{Q(x)}
$$

를 곱해 평균을 내면, $$P$$에서 샘플링한 것과 같은 기대값을 추정할 수 있습니다.

실무에서는 $$P/Q$$를 정확히 모르는 경우가 많아, 근사 모델을 쓰거나, self-normalized importance sampling을 사용하기도 합니다. self-normalized 형태는 다음과 같습니다.

$$
\hat{\mu}_{\text{SNIS}}=
\frac{\sum_{i=1}^{n} w(x_i) f(x_i)}{\sum_{i=1}^{n} w(x_i)},\quad x_i \sim Q
$$

이 형태는 편향이 생길 수 있으나, 분모 정규화로 분산이 줄어드는 장점이 있을 수 있어 상황에 따라 선택됩니다.

정책 기반 강화학습에서는 기존 정책이 만든 데이터(제안 분포)를 이용해 새 정책의 값을 추정할 때 중요도 샘플링을 활용할 수 있습니다. 새 정책이 기존 정책과 충분히 가까우면, 기존 정책 데이터로도 비교적 안정적인 추정이 가능해집니다.

## 맺음말

> 샘플링은 단순히 데이터를 일부만 고르는 기술이 아니라, 
> 모델이 어떤 세계를 보게 할지 결정하는 설계 요소입니다.

> 비확률 샘플링은 빠르게 시작할 수 있으나 선택 편향 위험이 크고, 
> 단순 무작위 샘플링은 희소 범주 누락 위험이 있습니다. 
> 층화와 가중 샘플링은 희소 범주를 보장하거나 목적에 맞게 표본을 구성하는 데 유용하며, 
> 스트리밍 환경에서는 리저버 샘플링이 대표성을 유지하는 표준 도구가 됩니다. 

> 목표 분포와 샘플링 분포가 다를 때는 중요도 샘플링 관점으로 “선택”과 “보정”을 함께 설계하는 것이 바람직합니다.
